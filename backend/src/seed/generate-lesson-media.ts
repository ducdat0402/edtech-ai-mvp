/**
 * Script: Generate image + video descriptions for each content item
 * 
 * Logic m·ªõi:
 * - M·ªói b√†i h·ªçc (content item) s·∫Ω c√≥ 3 d·∫°ng n·ªôi dung:
 *   1. VƒÉn b·∫£n (text) - ƒë√£ c√≥
 *   2. H√¨nh ·∫£nh (imageUrl) - c·∫ßn AI generate prompt
 *   3. Video (videoUrl) - c·∫ßn AI generate script
 * 
 * Script n√†y s·∫Ω:
 * - ƒê·ªçc t·ª´ng content item
 * - AI t·∫°o image prompt v√† video script d·ª±a tr√™n n·ªôi dung b√†i h·ªçc
 * - L∆∞u prompts v√†o media field ƒë·ªÉ s·ª≠ d·ª•ng sau n√†y
 */

import { NestFactory } from '@nestjs/core';
import { AppModule } from '../app.module';
import { Repository, IsNull, Not } from 'typeorm';
import { LearningNode } from '../learning-nodes/entities/learning-node.entity';
import { ContentItem } from '../content-items/entities/content-item.entity';
import { AiService } from '../ai/ai.service';
import { getRepositoryToken } from '@nestjs/typeorm';

interface MediaPrompts {
  imagePrompt: string;          // Prompt ƒë·ªÉ generate h√¨nh ·∫£nh v·ªõi AI (DALL-E, Midjourney, etc.)
  imageDescription: string;     // M√¥ t·∫£ h√¨nh ·∫£nh cho ng∆∞·ªùi d√πng
  videoScript: string;          // Script cho video (narration)
  videoDescription: string;     // M√¥ t·∫£ video
  videoDuration: string;        // ƒê·ªô d√†i video g·ª£i √Ω
}

async function generateMediaForDifficulty(
  aiService: AiService,
  contentItem: ContentItem,
  node: LearningNode,
  difficulty: string,
): Promise<MediaPrompts> {
  const difficultyDescriptions: Record<string, any> = {
    easy: {
      label: 'ƒê∆†N GI·∫¢N',
      imageStyle: 'H√¨nh ·∫£nh ƒë∆°n gi·∫£n, m√†u s·∫Øc t∆∞∆°i s√°ng, √≠t chi ti·∫øt, d·ªÖ hi·ªÉu ngay',
      videoStyle: 'Video ng·∫Øn (30-60s), ng√¥n ng·ªØ ƒë∆°n gi·∫£n, nhi·ªÅu animation vui nh·ªôn',
    },
    medium: {
      label: 'TRUNG B√åNH',
      imageStyle: 'H√¨nh ·∫£nh chi ti·∫øt v·ª´a ph·∫£i, c√≥ labels v√† annotations',
      videoStyle: 'Video trung b√¨nh (1-3 ph√∫t), gi·∫£i th√≠ch t·ª´ng b∆∞·ªõc, c√≥ v√≠ d·ª• th·ª±c t·∫ø',
    },
    hard: {
      label: 'N√ÇNG CAO',
      imageStyle: 'H√¨nh ·∫£nh chuy√™n s√¢u, bi·ªÉu ƒë·ªì ph·ª©c t·∫°p, nhi·ªÅu chi ti·∫øt k·ªπ thu·∫≠t',
      videoStyle: 'Video d√†i (3-5 ph√∫t), ph√¢n t√≠ch s√¢u, case studies ph·ª©c t·∫°p',
    },
  };

  const config = difficultyDescriptions[difficulty] || difficultyDescriptions.medium;

  // L·∫•y content text ƒë·ªÉ AI hi·ªÉu n·ªôi dung b√†i h·ªçc
  const contentText = contentItem.content || contentItem.title;

  const prompt = `B·∫°n l√† chuy√™n gia t·∫°o n·ªôi dung gi√°o d·ª•c ƒëa ph∆∞∆°ng ti·ªán. 
Nhi·ªám v·ª•: T·∫°o IMAGE PROMPT v√† VIDEO SCRIPT cho b√†i h·ªçc sau.

B√ÄI H·ªåC:
- Ti√™u ƒë·ªÅ: ${contentItem.title}
- Lo·∫°i: ${contentItem.type === 'concept' ? 'Kh√°i ni·ªám' : 'V√≠ d·ª•'}
- M·ª©c ƒë·ªô: ${config.label}
- Node: ${node.title}
- M√¥n h·ªçc: ${(node as any).subject?.name || 'Ch∆∞a x√°c ƒë·ªãnh'}

N·ªòI DUNG B√ÄI H·ªåC:
${contentText.substring(0, 2000)}

Y√äU C·∫¶U M·ª®C ƒê·ªò ${config.label}:
- Image: ${config.imageStyle}
- Video: ${config.videoStyle}

T·∫†O N·ªòI DUNG:

1. IMAGE PROMPT (ƒë·ªÉ d√πng v·ªõi DALL-E, Midjourney):
   - Prompt ti·∫øng Anh, chi ti·∫øt, m√¥ t·∫£ r√µ phong c√°ch v√† n·ªôi dung
   - Ph√π h·ª£p v·ªõi m·ª©c ƒë·ªô ${config.label}
   - Educational, professional style

2. IMAGE DESCRIPTION (m√¥ t·∫£ cho ng∆∞·ªùi d√πng):
   - Ti·∫øng Vi·ªát, 1-2 c√¢u
   - Gi·∫£i th√≠ch h√¨nh ·∫£nh minh h·ªça ƒëi·ªÅu g√¨

3. VIDEO SCRIPT (k·ªãch b·∫£n narration):
   - Ti·∫øng Vi·ªát
   - Ph√π h·ª£p ƒë·ªô d√†i video theo m·ª©c ƒë·ªô
   - Vi·∫øt script cho ng∆∞·ªùi ƒë·ªçc/AI voice

4. VIDEO DESCRIPTION (m√¥ t·∫£ video):
   - Ti·∫øng Vi·ªát, 1-2 c√¢u
   - T√≥m t·∫Øt n·ªôi dung video

5. VIDEO DURATION (ƒë·ªô d√†i g·ª£i √Ω):
   - V√≠ d·ª•: "30-60 gi√¢y", "1-2 ph√∫t", "3-5 ph√∫t"

Tr·∫£ v·ªÅ JSON:
{
  "imagePrompt": "English prompt for image generation...",
  "imageDescription": "M√¥ t·∫£ h√¨nh ·∫£nh b·∫±ng ti·∫øng Vi·ªát...",
  "videoScript": "Script video ti·∫øng Vi·ªát...",
  "videoDescription": "M√¥ t·∫£ video b·∫±ng ti·∫øng Vi·ªát...",
  "videoDuration": "ƒê·ªô d√†i g·ª£i √Ω..."
}`;

  const response = await aiService.chat([{ role: 'user', content: prompt }]);
  
  // Parse JSON response
  const cleanedResponse = response
    .replace(/```json\n?/g, '')
    .replace(/```\n?/g, '')
    .trim();

  try {
    return JSON.parse(cleanedResponse) as MediaPrompts;
  } catch (e) {
    // Fallback n·∫øu AI kh√¥ng tr·∫£ v·ªÅ JSON h·ª£p l·ªá
    return {
      imagePrompt: `Educational illustration for "${contentItem.title}", ${config.imageStyle.toLowerCase()}, clean modern design, educational content`,
      imageDescription: `H√¨nh ·∫£nh minh h·ªça cho b√†i h·ªçc "${contentItem.title}"`,
      videoScript: `Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi b√†i h·ªçc "${contentItem.title}". ${contentText.substring(0, 500)}...`,
      videoDescription: `Video h∆∞·ªõng d·∫´n v·ªÅ ${contentItem.title}`,
      videoDuration: difficulty === 'easy' ? '30-60 gi√¢y' : difficulty === 'hard' ? '3-5 ph√∫t' : '1-2 ph√∫t',
    };
  }
}

async function generateLessonMedia() {
  console.log('üé¨ Starting lesson media generation...');
  console.log('');
  console.log('Logic m·ªõi: M·ªói b√†i h·ªçc s·∫Ω c√≥ 3 d·∫°ng - TEXT + IMAGE + VIDEO');
  console.log('Script n√†y s·∫Ω t·∫°o image prompt v√† video script cho t·ª´ng b√†i h·ªçc');
  console.log('');

  const app = await NestFactory.createApplicationContext(AppModule);

  const nodeRepo = app.get<Repository<LearningNode>>(getRepositoryToken(LearningNode));
  const contentItemRepo = app.get<Repository<ContentItem>>(getRepositoryToken(ContentItem));
  const aiService = app.get(AiService);

  try {
    // L·∫•y t·∫•t c·∫£ content items c·∫ßn generate media
    // Ch·ªâ l·∫•y nh·ªØng item c√≥ content text (ƒë√£ c√≥ n·ªôi dung)
    const contentItems = await contentItemRepo.find({
      where: [
        { type: 'concept', content: Not(IsNull()) },
        { type: 'example', content: Not(IsNull()) },
      ],
      relations: ['node'],
      order: { nodeId: 'ASC', order: 'ASC' },
    });

    console.log(`üìö Found ${contentItems.length} content items to process`);

    // Nh√≥m theo node ƒë·ªÉ x·ª≠ l√Ω
    const itemsByNode = new Map<string, ContentItem[]>();
    for (const item of contentItems) {
      const nodeId = item.nodeId;
      if (!itemsByNode.has(nodeId)) {
        itemsByNode.set(nodeId, []);
      }
      itemsByNode.get(nodeId)!.push(item);
    }

    console.log(`üìñ Grouped into ${itemsByNode.size} nodes`);

    let processedCount = 0;
    let skippedCount = 0;
    let errorCount = 0;

    // X·ª≠ l√Ω t·ª´ng node
    for (const [nodeId, items] of itemsByNode) {
      // L·∫•y node info
      const node = await nodeRepo.findOne({
        where: { id: nodeId },
        relations: ['subject'],
      });

      if (!node) {
        console.log(`  ‚ö†Ô∏è Node ${nodeId} not found, skipping...`);
        skippedCount += items.length;
        continue;
      }

      console.log(`\nüìñ Processing node: "${node.title}" (${items.length} items)`);

      for (const item of items) {
        // Skip n·∫øu ƒë√£ c√≥ media prompts
        if (item.media?.imagePrompt || item.media?.videoScript) {
          console.log(`  ‚è≠Ô∏è "${item.title}" already has media prompts, skipping...`);
          skippedCount++;
          continue;
        }

        try {
          console.log(`  üé® Generating media for: "${item.title}" (${item.difficulty || 'medium'})...`);

          const mediaPrompts = await generateMediaForDifficulty(
            aiService,
            item,
            node,
            item.difficulty || 'medium',
          );

          // C·∫≠p nh·∫≠t media field
          item.media = {
            ...item.media,
            imagePrompt: mediaPrompts.imagePrompt,
            imageDescription: mediaPrompts.imageDescription,
            videoScript: mediaPrompts.videoScript,
            videoDescription: mediaPrompts.videoDescription,
            videoDuration: mediaPrompts.videoDuration,
          };

          // C·∫≠p nh·∫≠t format th√†nh 'mixed' v√¨ s·∫Ω c√≥ text + media
          item.format = 'mixed' as any;

          await contentItemRepo.save(item);

          console.log(`    ‚úÖ Generated: Image prompt (${mediaPrompts.imagePrompt.length} chars), Video script (${mediaPrompts.videoScript.length} chars)`);
          processedCount++;

          // Rate limiting - ƒë·ª£i 1.5 gi√¢y gi·ªØa c√°c items
          await new Promise(resolve => setTimeout(resolve, 1500));

        } catch (error: any) {
          console.error(`    ‚ùå Error: ${error.message}`);
          errorCount++;
        }
      }
    }

    console.log('\n' + '='.repeat(50));
    console.log('üìä SUMMARY:');
    console.log(`  - Processed: ${processedCount} content items`);
    console.log(`  - Skipped: ${skippedCount} items`);
    console.log(`  - Errors: ${errorCount}`);
    console.log('='.repeat(50));
    console.log('');
    console.log('üí° Next steps:');
    console.log('  1. Use imagePrompt to generate images with DALL-E/Midjourney');
    console.log('  2. Use videoScript to create videos with AI video tools');
    console.log('  3. Upload generated media and update imageUrl/videoUrl fields');

  } catch (error) {
    console.error('‚ùå Script failed:', error);
  } finally {
    await app.close();
  }
}

// Run the script
generateLessonMedia()
  .then(() => {
    console.log('\n‚úÖ Script completed successfully');
    process.exit(0);
  })
  .catch((error) => {
    console.error('\n‚ùå Script failed:', error);
    process.exit(1);
  });
